<!DOCTYPE html>
<html lang="en">
<head>
	<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-0.872831425-0.8"></script>
	<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());

	gtag('config', 'UA-0.872831425-0.8');
	</script> -->

	<!-- <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->

	<meta content="en-us" http-equiv="Content-Language">
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
	<title>Ruizhi Shao</title>
	<meta charset="utf-8">
	<style type="text/css">
		body {font-family: Calibri}
		a {text-decoration:none}
		a:any-link{color: darkred}
　　 	a:link{color:darkred;}
		a:visited{color:darkred;}
        /* a:hover{color:darkorange;} */

	</style>
</head>


<body style="width:80%;margin:auto" bgcolor="#FFFFFF">
	<table border="0" id="table1" style="margin-left: 8px">
		<tbody>
			<tr>
				<td width="323">
					<p align="center"><font face="Calibri"><img border="0" src="figs/me.jpg" height="224"></font></p>
				</td>
				<td >
					<p ><font style="font-size: 26pt;">&nbsp;Ruizhi Shao (邵睿智)<span lang="zh-cn"></span></font></p>

					<p style="margin-top: 3mm;margin-bottom: -0.8mm"><font face="Calibri" style="font-size: 14pt;" >&nbsp; Ph.d Student</font></p>
					<p style="margin-top: -0.8mm;margin-bottom: -0.8mm"><font face="Calibri" style="font-size: 14pt;">&nbsp; Department of Automation</font></p>
					<p style="margin-top: -0.8mm;margin-bottom: 3mm"><font face="Calibri" style="font-size: 14pt;">&nbsp; Tsinghua University (THU), Beijing, China</font></p>

					<p style="margin-top: 3mm;margin-bottom: -0.8mm"><font face="Calibri" style="font-size: 14pt;">&nbsp; <b>Email</b>:shaorz20@mails.tsinghua.edu.cn</font></p>
					&nbsp;
					<a href="Ruizhi_Shao_CV.pdf" style="font-size: 14pt;margin-top: -0.8mm;margin-bottom: 3mm"><b>CV</b></a> &bull;
					<a href="https://scholar.google.com/citations?user=Nm5TEGYAAAAJ&hl=en&oi=ao" style="font-size: 14pt;"><b>Google Scholar</b></a> &bull;
					<a href="https://github.com/DSaurus" style="font-size: 14pt;"><b>GitHub</b></a> &bull;
					<a href="https://twitter.com/RZ_Shao" style="font-size: 14pt;"><b>Twitter</b></a>
				</td>

			</tr>
		</tbody>
	</table>

<table style="margin-left: 55px;margin-right: 55px">
		<tbody>
			<td>
				<td style="border-style: none; border-width: medium;">
					<p style="margin-top: 3px; margin-bottom: 3px;"><font face="Calibri" style="font-size: 13pt;">
						<br>I am the 4th year Ph.D student from Tsinghua University.
						I have been doing researches at <a href="http://media.au.tsinghua.edu.cn/english/index/index.html"><b>Broadband Network & Digital Media Lab</b></a>
						advised by Professor <a href="http://liuyebin.com/"><b>Yebin Liu</b></a> in the field of artificial intelligence.
						My research interest typically lies in <b style="color: darkorange">3D vision</b>, <b style="color: darkorange">neural rendering</b>, <b style="color: darkorange">digital human</b>, <b style="color: darkorange">diffusion model</b> and their applications.
						<br>
						<br>
					</font></p>
				</td>
			</td>
		</tbody>
</table>

<p style="margin-left: 60px;margin-top: -30px"><b><font size="5"><br>
		News</font></b></p>
		<font style="font-size: 14pt; line-height: 1.25;">
			<ul style="margin-left: 60px;margin-top: -10px">
				<li><a>[March, 2024] 4 paper accepted by <b>CVPR 2024</b>!
				<li><a>[February, 2024] 1 paper accepted by <b>ICLR 2024</b>!
				<li><a>[March, 2023] 2 paper accepted by <b>CVPR 2023</b>! One of them accepted as <b>Highlight</b>!</li>
				<li><a>[August, 2022] 1 paper accepted by <b>SIGGRAPH Asia 2022</b>!</li>
				<li><a>[July, 2022] 2 paper accepted by <b>ECCV 2022</b>! One of them accepted as <b>Oral Presentation</b>!</li>
				<li><a>[March, 2022] 1 paper accepted by <b>CVPR 2022</b>!</li>
				<li><a>[July, 2021] 2 paper accepted by <b>ICCV 2021</b>!</li>
			</ul>
		</font>
<table style="width:80%;margin-left: 55px;">
	<tbody>
	<tr>
		<p style="margin-left: 60px;margin-bottom: -10px"><b><font size="5">
		Projects</font></b></p>
	</tr>
	<tr align="left">
		<td width="20%" valign="top"><p><img src="./figs/threestudio.jpg" width="240" alt="threestudio"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >ThreeStudio: A Unified Framework For 3D Content Creation </strong><br>
			Yuan-Chen Guo, Ying-Tian Liu, <span style="text-decoration: underline">Ruizhi Shao</span>, Christian Laforte, Vikram Voleti, Guan Luo, Chia-Hao Chen, Zi-Xin Zou, Chen Wang, Yan-Pei Cao and Song-Hai Zhang.<br>
			<b><a href="https://github.com/threestudio-project/threestudio">Project</a></b>
</table>
<table style="width:80%;margin-left: 55px;">
	<tbody>
	<tr>
		<p style="margin-left: 60px;margin-bottom: -10px"><b><font size="5">
		Publications and Manuscripts</font></b></p>
	</tr>
	<tr align="left">
		<td width="20%" valign="top"><p><video src="./figs/control4d.mp4" width="240" muted autoplay loop alt="control4d"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >Control4D: Efficient 4D Portrait Editing with Text </strong><br>
			<span style="text-decoration: underline">Ruizhi Shao</span>,  Jingxiang Sun, Cheng Peng, Zerong Zheng, Boyao Zhou, Hongwen Zhang, Yebin Liu.<br>
			<em>IEEE Conference on Computer Vision and Pattern Recognition</em>, 2024. <br>
			<a href="https://arxiv.org/abs/2305.20082"><b>Paper</b></a> |
			<b><a href="https://control4darxiv.github.io">Project</a></b> |
	<tr align="left">
		<td width="20%" valign="top"><p><img src="./figs/humannorm.png" width="240" alt="humannorm"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >HumanNorm: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation</strong><br>
			Xin Huang*, <span style="text-decoration: underline">Ruizhi Shao*</span>, Qi Zhang, Hongwen Zhang, Ying Feng, Yebin Liu, Qing Wang. (* equal contribution)<br>
			<em>IEEE Conference on Computer Vision and Pattern Recognition</em>, 2024. <br>
			<a href="https://arxiv.org/abs/2310.01406"><b>Paper</b></a> |
			<b><a href="https://humannorm.github.io">Project</a></b> |
	<tr align="left">
		<td width="20%" valign="top"><p><img src="./figs/holihand.png" width="240" alt="holihand"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >HHMR: Holistic Hand Mesh Recovery by Enhancing the Multimodal Controllability of Graph Diffusion Models</strong><br>
			Mengcheng Li, Hongwen Zhang, Yuxiang Zhang, <span style="text-decoration: underline">Ruizhi Shao</span>, Tao Yu, Yebin Liu.<br>
			<em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) </em>, 2024. <br>
			<!-- <a href=""><b>Paper</b></a> |
			<b><a href="">Project</a></b> | -->
	<tr align="left">
		<td width="20%" valign="top"><p><img src="./figs/gpsgaussian.png" width="240" alt="gpsgaussian"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >Gps-gaussian: Generalizable pixelwise 3d gaussian splatting for real-time human novel view synthesis</strong><br>
			Shunyuan Zheng, Boyao Zhou, <span style="text-decoration: underline">Ruizhi Shao</span>, Boning Liu, Shengping Zhang, Liqiang Nie, Yebin Liu.<br>
			<em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) </em>, 2024. <br>
			<a href="https://arxiv.org/pdf/2312.02155.pdf"><b>Paper</b></a> |
			<b><a href="https://shunyuanzheng.github.io/GPS-Gaussian">Project</a></b> |
			<b><a href="https://github.com/ShunyuanZheng/GPS-Gaussian">Code</a></b> |
	<tr align="left">
		<!-- <td width="20%" valign="top"><p><img src="./figs/control4d.jpg" width="240" alt="control4d"  align="top"></p></td> -->
		<td width="20%" valign="top"><p><video src="./figs/dreamcraft3d.mp4" width="240" muted autoplay loop alt="dreamcraft3d"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior</strong><br>
			Jingxiang Sun, Bo Zhang, <span style="text-decoration: underline">Ruizhi Shao</span>, Lizhen Wang, Wen Liu, Zhenda Xie, Yebin Liu
			<br>
			<em>International Conference on Learning Representations (<b>ICLR</b>)</em>, 2024. <br>
			<a href="https://arxiv.org/abs/2310.16818"><b>Paper</b></a> |
			<b><a href="https://mrtornado24.github.io/DreamCraft3D/">Project</a></b> |
	
	<tr align="left">
		<td width="20%" valign="top"><p><img src="./figs/tensor4d.gif" width="240" alt="tensor4d"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >Tensor4D : Efficient Neural 4D Decomposition for High-fidelity Dynamic Reconstruction and Rendering</strong><br>
			<span style="text-decoration: underline">Ruizhi Shao</span>, Zerong Zheng, Hanzhang Tu, Boning Liu, Hongwen Zhang, Yebin Liu.<br>
			<em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR Highlight</b>)</em>, 2023. <br>
			<a href="https://arxiv.org/pdf/2211.11610"><b>Paper</b></a> |
			<b><a href="https://liuyebin.com/tensor4d/tensor4d.html">Project</a></b> |
			<b><a href="https://github.com/DSaurus/Tensor4D">Code</a></b> |
			<b><a href="https://github.com/DSaurus/Tensor4D">Data</a></b> |
			</p></td></tr>
	<tr align="left">
		<td width="20%" valign="top"><p><img src="./figs/closet.png" width="240" alt="closet"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >CloSET: Modeling Clothed Humans on Continuous Surface with Explicit Template Decomposition</strong><br>
			Hongwen Zhang, Siyou Lin, <span style="text-decoration: underline">Ruizhi Shao</span>, Yuxiang Zhang, Zerong Zheng, Han Huang, Yandong Guo, Yebin Liu.<br>
			<em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2023. <br>
			<a href="http://www.liuyebin.com/closet/assets/CloSET_CVPR2023.pdf"><b>Paper</b></a> |
			<b><a href="http://www.liuyebin.com/closet/">Project</a></b> |
			</p></td></tr>
	<tr align="left">
		<td width="20%" valign="top"><p><img src="./figs/floren.jpg" width="240" alt="floren"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >FloRen: Real-time High-quality Human Performance Rendering via Appearance Flow Using Sparse RGB Cameras</strong><br>
			<span style="text-decoration: underline">Ruizhi Shao</span>, Liliang Chen, Zerong Zheng, Hongwen Zhang, Yuxiang Zhang, Han Huang, Yebin Liu.<br>
					<em>SIGGRAPH Asia</em>, 2022. <br>
			<a href="https://dl.acm.org/doi/abs/10.1145/3550469.3555409"><b>Paper</b></a> |
			</p></td></tr>

	<tr align="left">
		<td width="20%" valign="top"><p><img src="./figs/diffustereo.jpg" width="240" alt="diffustereo"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >DiffuStereo: High Quality Human Reconstruction via Diffusion-based Stereo Using Sparse Cameras</strong><br>
			<span style="text-decoration: underline">Ruizhi Shao</span>, Zerong Zheng, Hongwen Zhang, Jingxiang Sun, Yebin Liu.<br>
					<em>European Conference on Computer Vision (<b>ECCV ORAL</b>)</em>, 2022. <br>
			<a href="https://arxiv.org/abs/2207.08000"><b>Paper</b></a> |
			<b><a href="http://liuyebin.com/diffustereo/diffustereo.html">Project</a></b> |
			<b><a href="https://github.com/DSaurus/DiffuStereo">Code</a></b> |
			<b><a href="https://github.com/DSaurus/DiffuStereo">Data</a></b> |
			</p></td></tr>

	<tr align="left">
		<td width="20%" valign="top"><p><img src="./figs/fite.png" width="240" alt="FITE"  align="top"></p></td>
		<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
			<strong >Learning Implicit Templates for Point-Based Clothed Human Modeling</strong><br>
			Siyou Lin, Hongwen Zhang, Zerong Zheng, <span style="text-decoration: underline">Ruizhi Shao</span>, Yebin Liu.<br>
			<em>European Conference on Computer Vision (<b>ECCV</b>)</em>, 2022. <br>
			<a href="https://arxiv.org/abs/2207.06955"><b>Paper</b></a> |
			<b><a href="https://jsnln.github.io/fite/">Project</a></b> |
			<b><a href="https://github.com/jsnln/fite">Code</a></b> |
			</p></td></tr>

	<tr align="left">
	<td width="20%" valign="top"><p><img src="./figs/dbfield.jpg" width="240" alt="DoubleField"  align="top"></p></td>
	<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
		<strong >DoubleField: Bridging the Neural Surface and Radiance Fields for High-fidelity Human Reconstruction and Rendering</strong><br>
		<span style="text-decoration: underline">Ruizhi Shao</span>, Hongwen Zhang, He Zhang, Mingjia Chen, Yanpei Cao, Tao Yu, Yebin Liu.<br>
				<em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2022. <br>
		<a href="https://arxiv.org/abs/2106.03798"><b>Paper</b></a> |
		<b><a href="http://www.liuyebin.com/dbfield/dbfield.html">Project</a></b> |
		<b><a href="https://github.com/DSaurus/DoubleField">Code</a></b> |
		</p></td></tr>
	</tbody>

	<tr align="left">
	<td width="20%" valign="top"><p><img src="./figs/localtrans.jpg" width="240" alt="LocalTrans"  align="top"></p></td>
	<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
		<strong >LocalTrans: A Multiscale Local Transformer Network for Cross-Resolution Homography Estimation</strong><br>
		<span style="text-decoration: underline">Ruizhi Shao*</span>, Gaochang Wu*, Yuemei Zhou, Ying Fu, Lu Fang, Yebin Liu (* equal contribution)<br>
				<em>International Conference on Computer Vision (<b>ICCV</b>)</em>, 2021. <br>
		<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Shao_LocalTrans_A_Multiscale_Local_Transformer_Network_for_Cross-Resolution_Homography_Estimation_ICCV_2021_paper.pdf"><b>Paper</b></a> |
		<b><a href="http://www.liuyebin.com/localtrans/localtrans.html">Project</a></b> |
		<b><a href="https://github.com/DSaurus/LocalTrans">Code</a></b> |
		</p></td></tr>

	<tr align="left">
	<td width="20%" valign="top"><p><img src="./figs/deelmulticap.png" width="240" alt="DeepMultiCap"  align="top"></p></td>
	<td width="80%" valign="top"><p style="font-size: 14pt;line-height: 1.2;width: 14cm; margin-left: 10px">
		<strong >DeepMultiCap: Performance Capture of Multiple Characters Using Sparse Multiview Cameras</strong><br>
					Yang Zheng*, <span style="text-decoration: underline">Ruizhi Shao*</span>, Yuxiang Zhang, Tao Yu, Zerong Zheng, Qionghai Dai, Yebin Liu (* equal contribution)<br>
				<em>International Conference on Computer Vision (<b>ICCV</b>)</em>, 2021. <br>
		<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zheng_DeepMultiCap_Performance_Capture_of_Multiple_Characters_Using_Sparse_Multiview_Cameras_ICCV_2021_paper.html"><b>Paper</b></a> |
		<b><a href="http://www.liuyebin.com/dmc/dmc.html">Project</a></b> |
		<b><a href="https://github.com/DSaurus/DeepMultiCap">Code</a></b> |
		<b><a href="https://github.com/y-zheng18/MultiHuman-Dataset">Dataset</a></b>
		</p></td></tr>
</table>

<p style="margin-left: 60px;margin-top: -30px"><b><font size="5"><br>
		Honors and Awards</font></b></p>
		<font style="font-size: 14pt; line-height: 1.25;">
			<ul style="margin-left: 60px;margin-top: -10px">
				<li>Silver medal of the ACM/ICPC Asia-East Continent Final Contest, 2019.</li>
				<li>Innovation Award of Science and Technology, Nankai University, 2019.</li>
				<li>Silver medal of the ACM/ICPC Asia-East Continent Final Contest, 2018.</li>
				<li>China National Scholarship (highest scholarship given by the government of China), Nankai University, 2018.</li>
			</ul>
		</font>

<br>

</body>
</html>